{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       discourse_id      essay_id  \\\n0      0013cc385424  007ACE74B050   \n1      9704a709b505  007ACE74B050   \n2      c22adee811b6  007ACE74B050   \n3      a10d361e54e4  007ACE74B050   \n4      db3e453ec4e2  007ACE74B050   \n...             ...           ...   \n36760  9f63b687e76a  FFA381E58FC6   \n36761  9d5bd7d86212  FFA381E58FC6   \n36762  f1b78becd573  FFA381E58FC6   \n36763  cc184624ca8e  FFA381E58FC6   \n36764  c8a973681feb  FFA381E58FC6   \n\n                                          discourse_text  \\\n0      Hi, i'm Isaac, i'm going to be writing about h...   \n1      On my perspective, I think that the face is a ...   \n2      I think that the face is a natural landform be...   \n3      If life was on Mars, we would know by now. The...   \n4      People thought that the face was formed by ali...   \n...                                                  ...   \n36760  For many people they don't like only asking on...   \n36761  also people have different views and opinions ...   \n36762  Advice is something that can impact a persons ...   \n36763  someone can use everything that many people sa...   \n36764  In conclusion asking for an opinion can be ben...   \n\n             discourse_type discourse_effectiveness  \n0                      Lead                Adequate  \n1                  Position                Adequate  \n2                     Claim                Adequate  \n3                  Evidence                Adequate  \n4              Counterclaim                Adequate  \n...                     ...                     ...  \n36760                 Claim                Adequate  \n36761                 Claim                Adequate  \n36762              Position                Adequate  \n36763              Evidence             Ineffective  \n36764  Concluding Statement             Ineffective  \n\n[36765 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9704a709b505</td>\n      <td>007ACE74B050</td>\n      <td>On my perspective, I think that the face is a ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c22adee811b6</td>\n      <td>007ACE74B050</td>\n      <td>I think that the face is a natural landform be...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a10d361e54e4</td>\n      <td>007ACE74B050</td>\n      <td>If life was on Mars, we would know by now. The...</td>\n      <td>Evidence</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>db3e453ec4e2</td>\n      <td>007ACE74B050</td>\n      <td>People thought that the face was formed by ali...</td>\n      <td>Counterclaim</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36760</th>\n      <td>9f63b687e76a</td>\n      <td>FFA381E58FC6</td>\n      <td>For many people they don't like only asking on...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>36761</th>\n      <td>9d5bd7d86212</td>\n      <td>FFA381E58FC6</td>\n      <td>also people have different views and opinions ...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>36762</th>\n      <td>f1b78becd573</td>\n      <td>FFA381E58FC6</td>\n      <td>Advice is something that can impact a persons ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>36763</th>\n      <td>cc184624ca8e</td>\n      <td>FFA381E58FC6</td>\n      <td>someone can use everything that many people sa...</td>\n      <td>Evidence</td>\n      <td>Ineffective</td>\n    </tr>\n    <tr>\n      <th>36764</th>\n      <td>c8a973681feb</td>\n      <td>FFA381E58FC6</td>\n      <td>In conclusion asking for an opinion can be ben...</td>\n      <td>Concluding Statement</td>\n      <td>Ineffective</td>\n    </tr>\n  </tbody>\n</table>\n<p>36765 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./feedback-prize-effectiveness/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Load the data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data\n",
    "\n",
    "def tokenize_data(data):\n",
    "    \"\"\"\n",
    "    Tokenize the data\n",
    "    \"\"\"\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenized_data = []\n",
    "    for sentence in data:\n",
    "        tokenized_data.append(tokenizer(sentence, add_special_tokens=True,padding=True, truncation=True, max_length=512))\n",
    "    return tokenized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\joshz\\miniconda3\\envs\\kaggle-feedback\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "C:\\Users\\joshz\\miniconda3\\envs\\kaggle-feedback\\lib\\site-packages\\torch\\autograd\\__init__.py:175: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Same as before\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\"beep boop\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# This is new\n",
    "batch[\"labels\"] = torch.tensor([1, 1, 1])\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101, 10506,  2361, 22017,  2361,   102,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1, 1])}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'input_ids': [[101, 2023, 2003, 1996, 2034, 6251, 1012, 102], [101, 3693, 2033, 7592, 102, 0, 0, 0], [101, 7592, 2026, 2171, 2003, 3960, 102, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0]]},\n {'input_ids': [[101, 2023, 2003, 1996, 2117, 6251, 1012, 102], [101, 3693, 2033, 7592, 102, 0, 0, 0], [101, 7592, 2026, 2171, 2003, 3960, 102, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0]]}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenize_data([[\"This is the first sentence.\",\"Join me hello\",\"hello my name is bob\"],[\"This is the second sentence.\",\"Join me hello\",\"hello my name is bob\"]])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]', 'join', 'me', 'hello', '[SEP]', '[PAD]', '[PAD]', '[PAD]']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[0][\"input_ids\"][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b86b00f4a6a7738ca7c67ded81a44630775d778aee5f9abcc2b74c027e024cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}